<!DOCTYPE html>
<html lang="en">

<head>
    <title>handstand</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
</head>

<!-- this test webcam -> mediapipe workflow -->

<body>
    <style>
        body {
            background: #333;
            color: #ddd;
        }

        #overlay {
            position: absolute;
            z-index: 10;
            left: 0;
            top: 30px;
        }
    </style>

    <canvas id="overlay"></canvas>

    <!-- Require the peer dependencies of pose-detection. -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>

    <!-- You must explicitly require a TF.js backend if you're not using the TF.js union bundle. -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>

    <script src="pose.js"></script>
    <script src="handstand.js"></script>
    <script src="webcam.js"></script>

    <script async>
        const videoCameras = getConnectedDevices('videoinput');
        console.log('Cameras found:', videoCameras);

        var handstandTracker = new HandstandTracker();
        var analyzer;

        loadModel().then(() => {
            if (analyzer) analyzer.process();
        });

        const videoEl = setupVideoElement();
        captureWebcamTo(videoEl, () => {
            console.log('ok');
            analyzer = new Analyzer(videoEl);
            if (detector) analyzer.process();
        })
    </script>

</body>

</html>